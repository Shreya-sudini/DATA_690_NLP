{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chapter 3"
      ],
      "metadata": {
        "id": "7_gLXVWKV9cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "eU9jR-ZpXSfQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6"
      ],
      "metadata": {
        "id": "xItR7eQAWAK2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Y8fRx6BtV3Ko"
      },
      "outputs": [],
      "source": [
        "text = \"I have been to this really nice place where I saw a 2 big Jewels on The JAGUAR.!\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'[a-zA-Z]+', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUfCHdE8XVG0",
        "outputId": "cce3fb50-c0b2-4496-d9fc-6129d3fe080e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{I} {have} {been} {to} {this} {really} {nice} {place} {where} {I} {saw} {a} 2 {big} {Jewels} {on} {The} {JAGUAR}.!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[a-zA-Z]+ will match anything that is an alphabet"
      ],
      "metadata": {
        "id": "NhhoQqzFXpuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'[A-Z][a-z]*', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIq8mL-dXtcg",
        "outputId": "da16f00b-5c1e-4cd5-c3a1-8bf8327d61bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{I} have been to this really nice place where {I} saw a 2 big {Jewels} on {The} {J}{A}{G}{U}{A}{R}.!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[A-Z][a-z]* will find the words that start with uppercase letters and all the uppercase letters in the text"
      ],
      "metadata": {
        "id": "p-4W7_TfX0W7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'p[aeiou]{,2}t', text)\n",
        "len([w for w in text if re.search(r'p[aeiou]{,2}t', w)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR32vEhwaIbU",
        "outputId": "9a847018-21a4-4346-a494-e2e86548b132"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have been to this really nice place where I saw a 2 big Jewels on The JAGUAR.!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The experssion p[aeiou]{,2}t the word that has p and two instances of any vowels and ends with a t."
      ],
      "metadata": {
        "id": "8c7jNpxpa0FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'\\d+(\\.\\d+)?', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9t5ujPBbAqr",
        "outputId": "b7aef28c-8839-4174-d36d-728ed6d7829f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have been to this really nice place where I saw a {2} big Jewels on The JAGUAR.!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\d+(\\.\\d+)? expression identifies any numbers or decimals numbers present in the text"
      ],
      "metadata": {
        "id": "-zCLW1uPbTCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'([^aeiou][aeiou][^aeiou])*', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWVe5fcmbhC7",
        "outputId": "c0a3f5c3-ca91-497e-9cd2-4b6322f3097e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}I{} {hav}{}e{} {}b{}e{}e{}n{} {to }{}t{his}{} {}r{}e{}a{}l{}l{}y{} {nic}{}e{} {}p{lac}{}e{} {}w{her}{}e{} {}I{} {saw a }{}2{} {big}{} {Jew}{}e{}l{}s{ on}{} {}T{he }{}J{}A{}G{}U{}A{}R{}.{}!{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "([^aeiou][aeiou][^aeiou])* identifies any vowel in between non vowel characters such as her, nic."
      ],
      "metadata": {
        "id": "n7iSo2s9b4pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'\\w+|[^\\w\\s]+', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTu0wAn-cBfc",
        "outputId": "c0019cd8-a4d5-4149-fbb7-c4be35c0d0f8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{I} {have} {been} {to} {this} {really} {nice} {place} {where} {I} {saw} {a} {2} {big} {Jewels} {on} {The} {JAGUAR}{.!}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\w+|[^\\w\\s]+ will identify all alphanumeric words or the words that do now contain any characters or whitespaces. It essentially identifies all the tokens."
      ],
      "metadata": {
        "id": "DvGZO_0bcYUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7"
      ],
      "metadata": {
        "id": "0hyu_DulcqTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a\n",
        "text = \"I saw a big canyon which houses an apple and the canyon fire\"\n",
        "nltk.re_show(r'\\b(a|an|the)\\b', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-h85FBSdGb2",
        "outputId": "26ebd43b-1346-401c-ff8b-246b355176de"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I saw {a} big canyon which houses {an} apple and {the} canyon fire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b\n",
        "text = \"2*3+8 solve this\"\n",
        "nltk.re_show(r'\\d+(\\*\\d+|\\+\\d+)*', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-GgnXkrdYw3",
        "outputId": "ec4e0f2a-aa79-4203-dbdc-c4ce0c925cbe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2*3+8} solve this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21"
      ],
      "metadata": {
        "id": "HioXnX2Wec-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"words\")\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU6QlZi-e4yr",
        "outputId": "06890fae-4435-4db3-fd3d-e835e699bcd2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unknown(url):\n",
        "  html= urlopen(url).read()\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  raw = soup.get_text(separator=' ')\n",
        "  lower_case= re.findall(r'\\b[a-zA-Z]+(?:\\'[a-z]+)?\\b', raw)\n",
        "  word=set(nltk.corpus.words.words())\n",
        "  unknown= [w.strip() for w in lower_case if w not in word ]\n",
        "  return unknown"
      ],
      "metadata": {
        "id": "W5UswsHAegCS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://www.vox.com/recode/2019/10/16/20916712/cnn-democratic-presidential-debate-big-tech-silicon-valley-warren-harris\"\n",
        "result=unknown(url)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D5M1ezwgLqr",
        "outputId": "f6989dd3-6bf6-47fd-eaa3-59092a9e3346"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Democratic', 'debated', 'Big', 'Trump', 'banned', 'Twitter', 'Vox', 'Vox', 'homepage', 'Give', 'Give', 'Newsletters', 'Newsletters', 'Site', 'Search', 'Search', 'Vox', 'Explainers', 'Crossword', 'Video', 'Podcasts', 'Politics', 'Policy', 'Culture', 'Science', 'Technology', 'Climate', 'Health', 'Money', 'Life', 'Future', 'Perfect', 'Newsletters', 'More', 'Explainers', 'Hamas', 'Supreme', 'Court', 'Animal', 'Climate', 'What', 'All', 'explainers', 'Crossword', 'Video', 'Podcasts', 'Politics', 'Policy', 'Culture', 'Science', 'Technology', 'Climate', 'Health', 'Money', 'Life', 'Future', 'Perfect', 'Newsletters', 'Filed', 'Technology', 'Politics', 'Presidential', 'Election', 'simmering', 'Big', 'explodes', 'Democratic', 'And', 'By', 'Schleifer', 'teddyschleifer', 'Oct', 'EDT', 'Share', 'Share', 'Facebook', 'Share', 'Twitter', 'Share', 'Reddit', 'Share', 'All', 'sharing', 'options', 'Share', 'All', 'sharing', 'options', 'simmering', 'Big', 'explodes', 'Democratic', 'Reddit', 'Pocket', 'Flipboard', 'Email', 'Photo', 'Somodevilla', 'Getty', 'Images', 'Democrats', 'companies', 'bringing', 'simmering', 'Big', 'mainstream', 'Democratic', 'Democratic', 'candidates', 'minutes', 'topics', 'including', 'rights', 'companies', 'fundraising', 'Silicon', 'Valley', 'politicians', 'Trump', 'banned', 'Twitter', 'It', 'discussed', 'Democratic', 'sees', 'techlash', 'candidates', 'pressed', 'frontrunner', 'has', 'companies', 'Facebook', 'Many', 'competitors', 'whacks', 'Silicon', 'Valley', 'angles', 'Beto', 'Rourke', 'offered', 'comparing', 'Trump', 'We', 'businesses', 'companies', 'Rourke', 'That', 'Trump', 'has', 'sees', 'enemies', 'wants', 'It', 'Yang', 'infused', 'themes', 'diagnosing', 'using', 'Booker', 'laws', 'giants', 'He', 'harshest', 'companies', 'Steyer', 'indicated', 'monopolies', 'didn', 'specifics', 'companies', 'Sanders', 'sectors', 'Klobuchar', 'pushed', 'proposals', 'agencies', 'And', 'Castro', 'criticized', 'practices', 'companies', 'But', 'Kamala', 'represents', 'companies', 'Big', 'She', 'shifted', 'Twitter', 'Trump', 'showcased', 'candidates', 'Trump', 'Twitter', 'White', 'House', 'Join', 'Twitter', 'didn', 'Trump', 'Twitter', 'ignoring', 'attempts', 'rules', 'executives', 'candidates', 'has', 'enjoyed', 'companies', 'members', 'You', 'doors', 'executives', 'laws', 'If', 'Big', 'Big', 'executives', 'Democrats', 'attacking', 'angles', 'couldn', 'minutes', 'Democratic', 'Party', 'years', 'Vox', 'At', 'Vox', 'shouldn', 'That', 'Millions', 'Vox', 'forces', 'Support', 'Vox', 'Vox', 'One', 'Time', 'Monthly', 'Annual', 'Other', 'Yes', \"I'll\", 'Yes', \"I'll\", 'We', 'Apple', 'Pay', 'Google', 'Pay', 'You', 'In', 'This', 'Stream', 'Democratic', 'Dear', 'billionaires', 'simmering', 'Big', 'explodes', 'Democratic', 'answers', 'Democratic', 'View', 'stories', 'Next', 'Up', 'In', 'Technology', 'Most', 'Read', 'Supreme', 'Court', 'civilians', 'weapons', 'An', 'True', 'Detective', 'Night', 'Country', 'bonkers', 'But', 'has', 'changed', 'Take', 'newest', 'Vox', 'Alexei', 'Navalny', 'explained', 'vox', 'Sign', 'Today', 'Explained', 'Understand', 'stories', 'Thanks', 'signing', 'Check', 'inbox', 'email', 'Email', 'required', 'Oops', 'Something', 'Please', 'email', 'By', 'submitting', 'email', 'Terms', 'Privacy', 'Notice', 'You', 'This', 'protected', 'reCAPTCHA', 'Google', 'Privacy', 'Policy', 'Terms', 'Service', 'newsletters', 'newsletters', 'Subscribe', 'Latest', 'Living', 'By', 'Keren', 'Landman', 'MD', 'But', 'has', 'changed', 'By', 'Grady', 'Supreme', 'Court', 'civilians', 'weapons', 'By', 'Millhiser', 'An', 'True', 'Detective', 'Night', 'Country', 'bonkers', 'By', 'Aja', 'Romano', 'How', 'NIMBYs', 'immigrants', 'By', 'Levitz', 'Why', 'shouldn', 'By', 'Illing', 'Sign', 'Today', 'Explained', 'Understand', 'stories', 'Thanks', 'signing', 'Check', 'inbox', 'email', 'Email', 'required', 'Oops', 'Something', 'Please', 'email', 'By', 'submitting', 'email', 'Terms', 'Privacy', 'Notice', 'You', 'This', 'protected', 'reCAPTCHA', 'Google', 'Privacy', 'Policy', 'Terms', 'Service', 'newsletters', 'newsletters', 'Subscribe', 'Chorus', 'Facebook', 'Twitter', 'YouTube', 'About', 'Our', 'Privacy', 'Ethics', 'Guidelines', 'How', 'Contact', 'How', 'Vox', 'Contact', 'Send', 'Us', 'Tip', 'Vox', 'Vox', 'Vox', 'logo', 'Terms', 'Use', 'Privacy', 'Notice', 'Cookie', 'Policy', 'Do', 'Not', 'Sell', 'Share', 'My', 'Personal', 'Info', 'Licensing', 'FAQ', 'Accessibility', 'Platform', 'Status', 'Advertise', 'Jobs', 'Vox', 'Author', 'Login', 'Vox', 'LLC', 'All', 'Rights', 'Reserved']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When I using the html=nltk.clean.html() I was facing multiple errors says I should use BeautifulSoup() to properly clean the html page. Hence, I got this solution from the web."
      ],
      "metadata": {
        "id": "E9qVrxgs5w7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30"
      ],
      "metadata": {
        "id": "ByWFN7QglfJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens= [\"a\", \"hammer\", \" going\", \"bird \", \"tree\"]\n",
        "porter = nltk.PorterStemmer()\n",
        "lancaster = nltk.LancasterStemmer()"
      ],
      "metadata": {
        "id": "QCVnmxuVlgg7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter_text = [porter.stem(word) for word in tokens]\n",
        "lancaster_text = [lancaster.stem(word) for word in tokens]"
      ],
      "metadata": {
        "id": "xqRNtPMCnNjm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(porter_text)\n",
        "print(lancaster_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiczgDCpnYu9",
        "outputId": "5dc2a7f5-1413-4448-ae27-a6ad49f1cd9b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'hammer', ' go', 'bird ', 'tree']\n",
            "['a', 'ham', ' going', 'bird ', 'tre']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Lancaster stemmer seem to be more aggressive as it changed the 'hammer' to 'ham' and 'tree' to 'tre'. Accuracy wise Porter stemmer is doing a good job as it accurately modifies to the normal word forms."
      ],
      "metadata": {
        "id": "o1Y57tWMpVSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "39"
      ],
      "metadata": {
        "id": "Pm0DphoupV1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def soundex_digit(ch):\n",
        "    consonants = ['bfpv', 'cgjkqsxz', 'dt', 'l', 'mn', 'r']\n",
        "    for i in range(len(consonants)):\n",
        "        if ch.lower() in consonants[i]:\n",
        "            return str(i + 1)\n",
        "    return \"0\""
      ],
      "metadata": {
        "id": "lhgCeYc3GMC2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicates(text):\n",
        "    new_text = text[0]\n",
        "    for i in text[1:]:\n",
        "        if i != new_text[-1]:\n",
        "            new_text += i\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "fBGLfJZx2Unz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def soundex(name):\n",
        "    soundex = name[0].upper()\n",
        "    name = re.sub(r'[hw]', '', name[1:])\n",
        "    name = re.sub(r'[aeiouy]', '0', name)\n",
        "\n",
        "    new_name = ''\n",
        "    for n in name:\n",
        "        new_name += (re.sub(r'[^0]', soundex_digit(n), n))\n",
        "    name = new_name\n",
        "\n",
        "    name = remove_duplicates(name)\n",
        "\n",
        "    if soundex_digit(soundex) == name[0]:\n",
        "        name = name[1:]\n",
        "\n",
        "    name = re.sub(r'0', '', name)\n",
        "\n",
        "    if len(name) == 0:\n",
        "        return soundex + ('000')\n",
        "    soundex += name\n",
        "\n",
        "    if len(soundex) == 4:\n",
        "        return soundex\n",
        "    elif len(soundex) > 4:\n",
        "        return soundex[:4]\n",
        "    else:\n",
        "        while len(soundex) < 4:\n",
        "            soundex += \"0\"\n",
        "\n",
        "        return soundex"
      ],
      "metadata": {
        "id": "Nq0F2ENX2JjX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = [\"Robert\", \"Robert\", \"Rubin\", \"Ashcraft\", \"Ashcroft\"]\n",
        "\n",
        "print([soundex(n) for n in list1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0E7uwoS3Tdv",
        "outputId": "227f8bdc-fb6a-417a-dcda-6194ccb2f072"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['R163', 'R163', 'R150', 'A261', 'A261']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list2= [\"Robert\", \"robert\"]\n",
        "print([soundex(n) for n in list2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sagb3Wuk3vd7",
        "outputId": "f88a3596-a836-4c32-ba42-23096b845363"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['R163', 'R163']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chapter 4"
      ],
      "metadata": {
        "id": "_UIob_WBHknj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4"
      ],
      "metadata": {
        "id": "tQBr2E5tHmkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['is', 'NLP', 'fun', '?']\n",
        "tmp = words[0]\n",
        "words[0] = words[1]\n",
        "words[1] = tmp\n",
        "words[3] = '!'\n",
        "\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-jKGPgnHnj4",
        "outputId": "9e17b4ba-33f3-4520-9b02-ec231c939f50"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'is', 'fun', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tuple assignment\n",
        "words = ['is', 'NLP', 'fun', '?']\n",
        "words[0], words[1], words[3] = words[1], words[0], '!'\n",
        "\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLD0QSwLH-zT",
        "outputId": "cbc8e53e-51dc-4380-c769-aca9b00636ab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'is', 'fun', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20"
      ],
      "metadata": {
        "id": "fjUOAeEUIihA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_by_frequency(words):\n",
        "    word_freq = {}\n",
        "    for word in words:\n",
        "        if word in word_freq:\n",
        "            word_freq[word] += 1\n",
        "        else:\n",
        "            word_freq[word] = 1\n",
        "\n",
        "    sorted_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(sorted_freq)\n",
        "    sorted_words = [word for word, _ in sorted_freq]\n",
        "\n",
        "    return sorted_words\n",
        "\n",
        "words = ['table', 'chair', 'table', 'chair', 'table', 'chair', 'table', 'table', 'sofa', 'sofa', 'sofa', 'lamp']\n",
        "sorted_unique_words = sort_by_frequency(words)\n",
        "print(sorted_unique_words)"
      ],
      "metadata": {
        "id": "PJS5Ux_eInO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08563110-41d5-4084-a856-68abdc1363df"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('table', 5), ('chair', 3), ('sofa', 3), ('lamp', 1)]\n",
            "['table', 'chair', 'sofa', 'lamp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25"
      ],
      "metadata": {
        "id": "b3HTpYssIk2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(nltk.edit_distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-DSnV9_vJMy",
        "outputId": "e7b54cd5-0571-433f-a1e2-8626cb56abc0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function edit_distance in module nltk.metrics.distance:\n",
            "\n",
            "edit_distance(s1, s2, substitution_cost=1, transpositions=False)\n",
            "    Calculate the Levenshtein edit-distance between two strings.\n",
            "    The edit distance is the number of characters that need to be\n",
            "    substituted, inserted, or deleted, to transform s1 into s2.  For\n",
            "    example, transforming \"rain\" to \"shine\" requires three steps,\n",
            "    consisting of two substitutions and one insertion:\n",
            "    \"rain\" -> \"sain\" -> \"shin\" -> \"shine\".  These operations could have\n",
            "    been done in other orders, but at least three steps are needed.\n",
            "    \n",
            "    Allows specifying the cost of substitution edits (e.g., \"a\" -> \"b\"),\n",
            "    because sometimes it makes sense to assign greater penalties to\n",
            "    substitutions.\n",
            "    \n",
            "    This also optionally allows transposition edits (e.g., \"ab\" -> \"ba\"),\n",
            "    though this is disabled by default.\n",
            "    \n",
            "    :param s1, s2: The strings to be analysed\n",
            "    :param transpositions: Whether to allow transposition edits\n",
            "    :type s1: str\n",
            "    :type s2: str\n",
            "    :type substitution_cost: int\n",
            "    :type transpositions: bool\n",
            "    :rtype: int\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.edit_distance('kitten', 'sitting')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKQoLNP9vaK8",
        "outputId": "a2aec7b0-209f-4d03-f3aa-91754d9c4c84"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.edit_distance('light', 'dark')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWQIZUyqvlJB",
        "outputId": "cf29e057-dfd6-4b99-c153-f8c6c42109b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Levenshtein distance is a string metric to compute the difference between two strings. It is also called as edit distance.\n",
        "\n",
        "It uses a bottom up approach. It breaks down the problem into smaller ones and identifies smaller substrings and builds it until the distance is found. All the values are saved into a table.\n",
        "\n",
        "The dynamic programming approach saves time by not computing the same strings for many times."
      ],
      "metadata": {
        "id": "zShi2HXEvvDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26"
      ],
      "metadata": {
        "id": "e78uRZeKIlvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recursion_catalan(n):\n",
        "    if n <= 1:\n",
        "        return 1\n",
        "    else:\n",
        "        catalan = 0\n",
        "        for i in range(n):\n",
        "            catalan += recursion_catalan(i) * recursion_catalan(n - i - 1)\n",
        "        return catalan"
      ],
      "metadata": {
        "id": "37uCLVAUy4l-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "performance_recursion=timeit.timeit(lambda: recursion_catalan(5))\n",
        "print(performance_recursion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzpjSq0YzJpQ",
        "outputId": "a3744be0-c645-4a38-b8b9-c3442c9ff15f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26.403195705000144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def catalan_dynamic(n):\n",
        "    if n <= 1:\n",
        "        return 1\n",
        "    catalan=[0]*(n+1)\n",
        "    catalan[0] = catalan[1] = 1\n",
        "    for i in range(2, n + 1):\n",
        "        catalan[i] = 0\n",
        "        for j in range(i):\n",
        "            catalan[i] += catalan[j] * catalan[i - j - 1]\n",
        "\n",
        "    return catalan[n]"
      ],
      "metadata": {
        "id": "yu0_S8xk0DSe"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_dynamic=timeit.timeit(lambda: catalan_dynamic(5))\n",
        "print(performance_dynamic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8WVV0yc0wrq",
        "outputId": "f3da3238-cee9-4450-942a-46968914a71e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7974492049997934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear that the performance of dynamic program is better than the recursion."
      ],
      "metadata": {
        "id": "I4KBGuLdsywu"
      }
    }
  ]
}